{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entregable Grupo 13: Aprendizaje supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paquetes requeridos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn import model_selection\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import KBinsDiscretizer, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import sklearn.linear_model ##SVM\n",
    "import sklearn.neural_network ##SVM\n",
    "from sklearn import neural_network\n",
    "from sklearn import ensemble ##Random Forest\n",
    "import xgboost as xgb ##Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/travel_insurance_prediction_train.csv\")\n",
    "test_df = pd.read_csv(\"../data/travel_insurance_prediction_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realizaron distintas transformaciones de los atributos que implicaron la discretización de variables, la eliminación de aquellas poco relevantes y la conversión de atributos categóricos a variables dummy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada una de los datasets preprocesados se aplicaron técnicas de Validación Cruzada y Gridsearch para optimizar los hiperparámetros según la métrica elegica (f1_score).\n",
    "A continuación se presentan los Modelos con valores de F1 score macro average más altos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo 1: Algoritmo:  XGBOOST\n",
    "#### Preprocesado: Discretización de las features `Age` y `AnnualIncome`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = make_column_transformer(\n",
    "    (KBinsDiscretizer(n_bins=5, encode=\"onehot-dense\", strategy=\"quantile\"), [\"Age\", \"AnnualIncome\"]),\n",
    "    (OneHotEncoder(categories=\"auto\", dtype=\"int\", handle_unknown=\"ignore\"),\n",
    "     [\"Employment Type\", \"GraduateOrNot\", \"FamilyMembers\", \"FrequentFlyer\", \"EverTravelledAbroad\"]),\n",
    "    remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = transformer.fit_transform(train_df.drop(columns=[\"Customer\", \"TravelInsurance\"]))\n",
    "y_train = train_df[\"TravelInsurance\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=transformer.transform(test_df.drop(columns=[\"Customer\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### División de los datos en train y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(X_train, y_train, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:08:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:08:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arrua\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=0.0001, base_score=0.5, booster='gbtree',\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.4, max_delta_step=0,\n",
       "              max_depth=7, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=5, n_jobs=12,\n",
       "              num_parallel_tree=1, objetive='binary:logistic', random_state=0,\n",
       "              reg_alpha=9.99999975e-05, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xg_reg=xgb.XGBClassifier(alpha=0.0001, colsample_bytree=1,\n",
    "              learning_rate=0.4, max_depth=7,           \n",
    "              n_estimators=5, objetive=\"binary:logistic\")\n",
    "best_xg_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTRENAMIENTO\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88       751\n",
      "           1       0.89      0.62      0.73       441\n",
      "\n",
      "    accuracy                           0.83      1192\n",
      "   macro avg       0.85      0.79      0.80      1192\n",
      "weighted avg       0.84      0.83      0.82      1192\n",
      "\n",
      "TESTEO\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92       207\n",
      "           1       0.91      0.67      0.77        91\n",
      "\n",
      "    accuracy                           0.88       298\n",
      "   macro avg       0.89      0.82      0.84       298\n",
      "weighted avg       0.88      0.88      0.87       298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_best= best_xg_reg.predict(X_train)\n",
    "y_val_pred_best= best_xg_reg.predict(X_val)\n",
    "\n",
    "print(\"ENTRENAMIENTO\")\n",
    "print(classification_report(y_train, y_train_pred_best))\n",
    "\n",
    "print(\"TESTEO\")\n",
    "print(classification_report(y_val, y_val_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo 2: Algoritmo:  RandomForestClassifier\n",
    "#### Preprocesado: Discretización de las features `Age`,  `AnnualIncome` y `FamilyMembers` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = make_column_transformer(\n",
    "    (KBinsDiscretizer(n_bins=5, encode=\"onehot-dense\", strategy=\"quantile\"), [\"Age\", \"AnnualIncome\"]),(KBinsDiscretizer(n_bins=4, encode=\"onehot-dense\", strategy=\"quantile\"), [\"FamilyMembers\"]),\n",
    "    (OneHotEncoder(categories=\"auto\", dtype=\"int\", handle_unknown=\"ignore\"),\n",
    "     [\"Employment Type\", \"GraduateOrNot\", \"FrequentFlyer\", \"EverTravelledAbroad\"]),\n",
    "    remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = transformer.fit_transform(train_df.drop(columns=[\"Customer\", \"TravelInsurance\"]))\n",
    "y_train = train_df[\"TravelInsurance\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=transformer.transform(test_df.drop(columns=[\"Customer\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### División de los datos en train y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(X_train, y_train, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, min_samples_leaf=4, n_estimators=20,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_RM=ensemble.RandomForestClassifier(max_depth=10, min_samples_leaf=4, n_estimators=20,\n",
    "                       random_state=42)\n",
    "best_RM.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTRENAMIENTO\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87       751\n",
      "           1       0.89      0.59      0.71       441\n",
      "\n",
      "    accuracy                           0.82      1192\n",
      "   macro avg       0.85      0.78      0.79      1192\n",
      "weighted avg       0.83      0.82      0.81      1192\n",
      "\n",
      "TESTEO\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       207\n",
      "           1       0.92      0.66      0.77        91\n",
      "\n",
      "    accuracy                           0.88       298\n",
      "   macro avg       0.90      0.82      0.84       298\n",
      "weighted avg       0.88      0.88      0.87       298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_best= best_RM.predict(X_train)\n",
    "y_val_pred_best= best_RM.predict(X_val)\n",
    "\n",
    "print(\"ENTRENAMIENTO\")\n",
    "print(classification_report(y_train, y_train_pred_best))\n",
    "\n",
    "print(\"TESTEO\")\n",
    "print(classification_report(y_val, y_val_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Modelo 3: Algoritmo:  SVM\n",
    "#### Preprocesado: Discretización de las features `Age`,  `AnnualIncome` y `FamilyMembers` (utilizado en paso anterior) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm=sklearn.svm.SVC(C=1)\n",
    "best_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTRENAMIENTO\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87       751\n",
      "           1       0.90      0.58      0.71       441\n",
      "\n",
      "    accuracy                           0.82      1192\n",
      "   macro avg       0.85      0.77      0.79      1192\n",
      "weighted avg       0.83      0.82      0.81      1192\n",
      "\n",
      "TESTEO\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       207\n",
      "           1       0.92      0.66      0.77        91\n",
      "\n",
      "    accuracy                           0.88       298\n",
      "   macro avg       0.90      0.82      0.84       298\n",
      "weighted avg       0.88      0.88      0.87       298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_best= best_svm.predict(X_train)\n",
    "y_val_pred_best= best_svm.predict(X_val)\n",
    "\n",
    "print(\"ENTRENAMIENTO\")\n",
    "print(classification_report(y_train, y_train_pred_best))\n",
    "\n",
    "print(\"TESTEO\")\n",
    "print(classification_report(y_val, y_val_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Modelo 4: Algoritmo:  XGBOOST\n",
    "#### Preprocesado:  Modificación de la cantidad de bins de las variables a discretizar y eliminación de la columna no relevante `ChronicDiseases`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = make_column_transformer(\n",
    "    (KBinsDiscretizer(n_bins=5, encode=\"onehot-dense\", strategy=\"quantile\"), [\"Age\", \"FamilyMembers\"]), (KBinsDiscretizer(n_bins=6, encode=\"onehot-dense\", strategy=\"quantile\"), [\"AnnualIncome\"]),\n",
    "    (OneHotEncoder(categories=\"auto\", dtype=\"int\", handle_unknown=\"ignore\"),\n",
    "     [\"Employment Type\", \"FrequentFlyer\", \"EverTravelledAbroad\", \"GraduateOrNot\"]),\n",
    "    remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = transformer.fit_transform(train_df.drop(columns=[\"Customer\", \"TravelInsurance\", \"ChronicDiseases\"]))\n",
    "y_train = train_df[\"TravelInsurance\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = transformer.transform(test_df.drop(columns=[\"Customer\", \"ChronicDiseases\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### División de los datos en train y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(X_train, y_train, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:09:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:09:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arrua\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=0.0001, base_score=0.5, booster='gbtree',\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.2, max_delta_step=0,\n",
       "              max_depth=4, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=1, n_jobs=12,\n",
       "              num_parallel_tree=1, objetive='binary:logistic', random_state=0,\n",
       "              reg_alpha=9.99999975e-05, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xg_reg=xgb.XGBClassifier(alpha=0.0001, colsample_bytree=1, \n",
    "              learning_rate=0.2, max_depth=4,           \n",
    "              n_estimators=1, objetive=\"binary:logistic\")\n",
    "best_xg_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTRENAMIENTO\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.97      0.87       751\n",
      "           1       0.91      0.58      0.70       441\n",
      "\n",
      "    accuracy                           0.82      1192\n",
      "   macro avg       0.85      0.77      0.79      1192\n",
      "weighted avg       0.84      0.82      0.81      1192\n",
      "\n",
      "TESTEO\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       207\n",
      "           1       0.94      0.66      0.77        91\n",
      "\n",
      "    accuracy                           0.88       298\n",
      "   macro avg       0.90      0.82      0.85       298\n",
      "weighted avg       0.89      0.88      0.88       298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_best= best_xg_reg.predict(X_train)\n",
    "y_val_pred_best= best_xg_reg.predict(X_val)\n",
    "\n",
    "print(\"ENTRENAMIENTO\")\n",
    "print(classification_report(y_train, y_train_pred_best))\n",
    "\n",
    "print(\"TESTEO\")\n",
    "print(classification_report(y_val, y_val_pred_best))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
